import numpy as npfrom scipy.stats import binomclass smc_res:    """Container class to store result of Sequential Monte Carlo filter."""    def __init__(self, alpha_filt, particles=None, W=None, ancestor_indices=None, logW=None, N_eff = None, logZ = None):        self.alpha_filt = alpha_filt  # Filtered state estimates        self.particles = particles  # All particles        self.ancestor_indices = ancestor_indices  # All ancestor indices        self.logW = logW  # logarithm of unnormalized importance weights        self.W = W  # Normalized importance weights        self.N_eff = N_eff  # Effective number of samples        self.logZ = logZ  # logarithm of marginal likelihood estimate        def binomial_rng(n, p, size=None):    """    Draw samples from a binomial distribution using np.random.binomial, but    with an explicit type cast from float64 to int32 (unsafe).    Parameters    ----------    n : int or array_like of ints        Parameter of the distribution, >= 0. Floats are also accepted,        but they will be truncated to integers.    p : float or array_like of floats        Parameter of the distribution, >= 0 and <=1.    size : int or tuple of ints, optional        Output shape.  If the given shape is, e.g., ``(m, n, k)``, then        ``m * n * k`` samples are drawn.  If size is ``None`` (default),        a single value is returned if ``n`` and ``p`` are both scalars.        Otherwise, ``np.broadcast(n, p).size`` samples are drawn.        Returns    -------    samples : ndarray or scalar        Drawn samples from the parameterized binomial distribution, where        each sample is equal to the number of successes over the n trials.    """    return np.random.binomial(np.int32(n), p, size)class Param:    def __init__(self, pse, pei, pir, pic, rho, sigma_epsilon, init_mean, population_size):                self.pse = pse        self.pei = pei        self.pir = pir        self.pic = pic        self.rho = rho        self.sigma_epsilon = sigma_epsilon        self.init_mean = init_mean        self.population_size = population_sizeclass SEIR:    def __init__(self, param: Param):        self.d  = 4  # Number of states. S+E+I+R, but R is deterministc so we only represent S+E+I in state vector. Extra state for z        self.dy = 1  # ICU measurements        self.param = param            def set_param(self, rho):        """        Sets the "rho parameter" of the model to the provided value.        :param rho: float, update the model to use this value for rho.        """        self.param.rho = rho    def log_lik(self, y, alpha):        """        Computes the observation log-likelihood, log p(y_t|alpha_t), for all values in array alpha_t        Parameters        ----------        y : int or float            Observation at time t (number of ICU cases)        alpha : ndarray            Array of size (d,N) where each column is a state vector.        Returns        -------        ndarray            Array of size (1,N) with log-likelihood values.        """                if y.item() is not None:            # Binomial likelihood            return binom.logpmf(y.item(), alpha[2, :], self.param.pic)        else:            # Missing observation, return all zeros.            return np.zeros((1, alpha.shape[1]))    def sample_state(self, alpha0=None, N=1):        """        Samples N state vectors from the model dynamics, p(alpha_t | alpha_{t-1})        Parameters        ----------        alpha0 : ndarray or None, optional            If array of size (d,N), the i:th column contains the state vector            that we condition the i:th sample on (i.e., alpha_{t-1}^i).                        If array of size (d,1) we use the same state vector for all N samples.                        If None, the samples are generated from the initial distribution p(alpha_1)-                        The default is None.                    N : int, optional            The number of samples to generate. If alpha0 is of size (d,N) with            N > 1, then the value of N must match the size of alpha0. The default is 1.        Returns        -------        alpha1 : ndarray            Array of size (d,N) where the i:th column contains the i:th sample (i.e., alpha_t^i).                    """                        if alpha0 is None:  # Initialize            alpha1 = np.zeros((self.d, N), dtype=float)            # The S,E,I states are sampled from binomial distributions with the specified means            s0 = self.param.init_mean[0]            e0 = self.param.init_mean[1]            i0 = self.param.init_mean[2]                        alpha1[0, :] = binomial_rng(self.param.population_size, s0 / self.param.population_size, size=N)            alpha1[1, :] = binomial_rng(self.param.population_size, e0 / self.param.population_size, size=N)            alpha1[2, :] = binomial_rng(self.param.population_size, i0 / self.param.population_size, size=N)            # Initial state for z            alpha1[3, :] = np.random.normal(loc=self.param.init_mean[3], scale=1, size=N)        else:  # Propagate            b = np.exp(alpha0[3,:])  # Compute b[t]            rate = 1 - (1-self.param.pse)*np.exp(-self.param.rho * b * alpha0[2,:] / self.param.population_size)                      de = binomial_rng(alpha0[0, :], rate, size=N)            di = binomial_rng(alpha0[1, :], self.param.pei, size=N)            dr = binomial_rng(alpha0[2, :], self.param.pir, size=N)            dz = np.random.normal(loc = 0., scale=self.param.sigma_epsilon, size=N)            alpha1 = alpha0 + [-de, de - di, di - dr, dz]        return alpha1        def sample_obs(self, alpha):        """        Samples observation from p(y_t | alpha_t)        Parameters        ----------        alpha : ndarray            Array of size (d,N) where each column is a state vector.        Returns        -------        y : int or ndarray            If N = 1, a single sample from the observation model is generated            If N > 1, array of size (N,) where the i:th sample is sampled conditionally            on the i:th column of alpha.        """                y = binomial_rng(alpha[2, :], self.param.pic)        return y        def simulate(self, T, N=1):        """        Simulates the SEIR model for a given number of time steps. Multiple trajectories        can be simulated simulataneously.        Parameters        ----------        T : int            Number of time steps to simulate the model for.        N : int, optional            Number of independent trajectories to simulate. The default is 1.        Returns        -------        alpha : ndarray            Array of size (d,N,T) with state trajectories. alpha[:,i,:] is the i:th trajectory.        y : ndarray            Array of size (1,N,T) with observations.        """                        # We work with 3d arrays for the states/obs (d,N,T)        alpha = np.zeros((self.d, N, T), dtype=np.float64)  # We use floats to store the state vector because the last state (z) is a real number        y = np.zeros((self.dy, N, T), dtype=np.int32)        for t in range(T):            if t == 0:                # Initialize by calling the sample_state function without conditioning                alpha[:, :, 0] = self.sample_state(N=N)            else:                # Sample the next time step (propagate)                alpha[:, :, t] = self.sample_state(alpha[:, :, t - 1], N=N)            # Sample the observation            y[0, :, t] = self.sample_obs(alpha[:, :, t])        return alpha, y